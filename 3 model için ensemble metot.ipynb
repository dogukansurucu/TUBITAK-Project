{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7add464d-abe4-497d-996c-6477783b0001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "118/118 - 2s - loss: 0.0385 - val_loss: 0.0180 - 2s/epoch - 15ms/step\n",
      "Epoch 2/100\n",
      "118/118 - 0s - loss: 0.0202 - val_loss: 0.0127 - 241ms/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "118/118 - 0s - loss: 0.0166 - val_loss: 0.0115 - 242ms/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "118/118 - 0s - loss: 0.0154 - val_loss: 0.0110 - 252ms/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "118/118 - 0s - loss: 0.0148 - val_loss: 0.0106 - 258ms/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "118/118 - 0s - loss: 0.0142 - val_loss: 0.0100 - 259ms/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "118/118 - 0s - loss: 0.0136 - val_loss: 0.0093 - 257ms/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "118/118 - 0s - loss: 0.0129 - val_loss: 0.0087 - 261ms/epoch - 2ms/step\n",
      "Epoch 9/100\n",
      "118/118 - 0s - loss: 0.0123 - val_loss: 0.0081 - 265ms/epoch - 2ms/step\n",
      "Epoch 10/100\n",
      "118/118 - 0s - loss: 0.0117 - val_loss: 0.0076 - 261ms/epoch - 2ms/step\n",
      "Epoch 11/100\n",
      "118/118 - 0s - loss: 0.0112 - val_loss: 0.0072 - 258ms/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "118/118 - 0s - loss: 0.0107 - val_loss: 0.0069 - 262ms/epoch - 2ms/step\n",
      "Epoch 13/100\n",
      "118/118 - 0s - loss: 0.0102 - val_loss: 0.0066 - 246ms/epoch - 2ms/step\n",
      "Epoch 14/100\n",
      "118/118 - 0s - loss: 0.0098 - val_loss: 0.0064 - 248ms/epoch - 2ms/step\n",
      "Epoch 15/100\n",
      "118/118 - 0s - loss: 0.0095 - val_loss: 0.0063 - 250ms/epoch - 2ms/step\n",
      "Epoch 16/100\n",
      "118/118 - 0s - loss: 0.0092 - val_loss: 0.0062 - 258ms/epoch - 2ms/step\n",
      "Epoch 17/100\n",
      "118/118 - 0s - loss: 0.0089 - val_loss: 0.0061 - 272ms/epoch - 2ms/step\n",
      "Epoch 18/100\n",
      "118/118 - 0s - loss: 0.0086 - val_loss: 0.0061 - 260ms/epoch - 2ms/step\n",
      "Epoch 19/100\n",
      "118/118 - 0s - loss: 0.0084 - val_loss: 0.0061 - 258ms/epoch - 2ms/step\n",
      "Epoch 20/100\n",
      "118/118 - 0s - loss: 0.0082 - val_loss: 0.0061 - 246ms/epoch - 2ms/step\n",
      "Epoch 21/100\n",
      "118/118 - 0s - loss: 0.0080 - val_loss: 0.0061 - 255ms/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "118/118 - 0s - loss: 0.0079 - val_loss: 0.0062 - 255ms/epoch - 2ms/step\n",
      "Epoch 23/100\n",
      "118/118 - 0s - loss: 0.0077 - val_loss: 0.0063 - 248ms/epoch - 2ms/step\n",
      "Epoch 24/100\n",
      "118/118 - 0s - loss: 0.0076 - val_loss: 0.0063 - 269ms/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "118/118 - 0s - loss: 0.0075 - val_loss: 0.0064 - 246ms/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "118/118 - 0s - loss: 0.0074 - val_loss: 0.0065 - 250ms/epoch - 2ms/step\n",
      "Epoch 27/100\n",
      "118/118 - 0s - loss: 0.0073 - val_loss: 0.0066 - 250ms/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "118/118 - 0s - loss: 0.0072 - val_loss: 0.0067 - 253ms/epoch - 2ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "Mean Squared Error (MSE): 0.0017\n",
      "Root Mean Squared Error (RMSE): 0.0417\n",
      "Mean Absolute Error (MAE): 0.03122273337036938\n",
      "Mean Absolute Percentage Error (MAPE): 0.30241950063576745\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Veriyi yükleme ve ön işleme\n",
    "df = pd.read_excel(\"rainfall-and-daily-consumption-data-on-istanbul-dams.xlsx\")\n",
    "\n",
    "df = df[['Tarih', 'İstanbul günlük tüketim(m³/gün)']]\n",
    "df = df.set_index(\"Tarih\")\n",
    "df.index = pd.to_datetime(df.index)\n",
    "df['İstanbul günlük tüketim(m³/gün)'] = df['İstanbul günlük tüketim(m³/gün)'] // 100\n",
    "df['İstanbul günlük tüketim(m³/gün)'] = df['İstanbul günlük tüketim(m³/gün)'].astype(float)\n",
    "df = np.log(df)\n",
    "\n",
    "# Eğitim ve test veri setlerini ayırma\n",
    "train_size = int(len(df) * 0.80)\n",
    "test_size = len(df) - train_size\n",
    "train, test = df[0:train_size], df[train_size:len(df)]\n",
    "\n",
    "# Özellikleri oluşturma\n",
    "def create_features(df):\n",
    "    df = df.copy()\n",
    "    df['dayofweek'] = df.index.dayofweek\n",
    "    df['quarter'] = df.index.quarter\n",
    "    df['month'] = df.index.month\n",
    "    df['year'] = df.index.year\n",
    "    df['dayofyear'] = df.index.dayofyear\n",
    "    return df\n",
    "\n",
    "df = create_features(df)\n",
    "train = create_features(train)\n",
    "test = create_features(test)\n",
    "\n",
    "FEATURES = ['dayofweek', 'quarter', 'month', 'year', 'dayofyear']\n",
    "TARGET = 'İstanbul günlük tüketim(m³/gün)'\n",
    "\n",
    "X_train = train[FEATURES]\n",
    "y_train = train[TARGET]\n",
    "\n",
    "X_test = test[FEATURES]\n",
    "y_test = test[TARGET]\n",
    "\n",
    "# Veriyi normalize etme\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "X_train = scaler_X.fit_transform(X_train)\n",
    "X_test = scaler_X.transform(X_test)\n",
    "\n",
    "y_train = scaler_y.fit_transform(y_train.values.reshape(-1, 1)).ravel()\n",
    "y_test = scaler_y.transform(y_test.values.reshape(-1, 1)).ravel()\n",
    "\n",
    "# LSTM için veriyi yeniden şekillendirme\n",
    "X_train = np.array(X_train).reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = np.array(X_test).reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "# LSTM modelini oluşturma\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Erken durdurma tanımlama\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Modeli eğitme\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), verbose=2, shuffle=False, callbacks=[early_stopping])\n",
    "\n",
    "# Test verileri üzerinde tahmin yapma\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Tahminleri orijinal ölçeğe döndürme\n",
    "y_test_orig = scaler_y.inverse_transform(y_test.reshape(-1, 1))\n",
    "y_pred_orig = scaler_y.inverse_transform(y_pred.reshape(-1, 1))\n",
    "\n",
    "# MSE ve RMSE değerlerini hesaplama\n",
    "mse = mean_squared_error(y_test_orig, y_pred_orig)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(\"Mean Squared Error (MSE): {:.4f}\".format(mse))\n",
    "print(\"Root Mean Squared Error (RMSE): {:.4f}\".format(rmse))\n",
    "\n",
    "# MAE hesaplama\n",
    "mae = mean_absolute_error(y_test_orig, y_pred_orig)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "\n",
    "# MAPE hesaplama\n",
    "mape = mean_absolute_percentage_error(y_test_orig, y_pred_orig) * 100\n",
    "print(\"Mean Absolute Percentage Error (MAPE):\", mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7d2ab67b-4e78-45dd-988e-7c77ba85832f",
   "metadata": {},
   "outputs": [],
   "source": [
    "LstmYPRED= y_pred_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1349d818-8d59-4e0d-9807-4b5bcb0bbc20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.0024\n",
      "Root Mean Squared Error (RMSE): 0.0485\n",
      "Mean Absolute Error (MAE): 0.038298088621056846\n",
      "Mean Absolute Percentage Error (MAPE): 0.3716887542262685\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Veriyi yükleme ve ön işleme\n",
    "df = pd.read_excel(\"rainfall-and-daily-consumption-data-on-istanbul-dams.xlsx\")\n",
    "\n",
    "df = df[['Tarih', 'İstanbul günlük tüketim(m³/gün)']]\n",
    "df = df.set_index(\"Tarih\")\n",
    "df.index = pd.to_datetime(df.index)\n",
    "df['İstanbul günlük tüketim(m³/gün)'] = df['İstanbul günlük tüketim(m³/gün)'] // 100\n",
    "df['İstanbul günlük tüketim(m³/gün)'] = df['İstanbul günlük tüketim(m³/gün)'].astype(float)\n",
    "df = np.log(df)\n",
    "\n",
    "# Eğitim ve test veri setlerini ayırma\n",
    "train_size = int(len(df) * 0.80)\n",
    "test_size = len(df) - train_size\n",
    "train, test = df[0:train_size], df[train_size:len(df)]\n",
    "\n",
    "# Özellikleri oluşturma\n",
    "def create_features(df):\n",
    "    df = df.copy()\n",
    "    df['dayofweek'] = df.index.dayofweek\n",
    "    df['quarter'] = df.index.quarter\n",
    "    df['month'] = df.index.month\n",
    "    df['year'] = df.index.year\n",
    "    df['dayofyear'] = df.index.dayofyear\n",
    "    return df\n",
    "\n",
    "df = create_features(df)\n",
    "train = create_features(train)\n",
    "test = create_features(test)\n",
    "\n",
    "FEATURES = ['dayofweek', 'quarter', 'month', 'year', 'dayofyear']\n",
    "TARGET = 'İstanbul günlük tüketim(m³/gün)'\n",
    "\n",
    "X_train = train[FEATURES]\n",
    "y_train = train[TARGET]\n",
    "\n",
    "X_test = test[FEATURES]\n",
    "y_test = test[TARGET]\n",
    "\n",
    "# Veriyi normalize etme\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "X_train = scaler_X.fit_transform(X_train)\n",
    "X_test = scaler_X.transform(X_test)\n",
    "\n",
    "y_train = scaler_y.fit_transform(y_train.values.reshape(-1, 1)).ravel()\n",
    "y_test = scaler_y.transform(y_test.values.reshape(-1, 1)).ravel()\n",
    "\n",
    "# MLPRegressor modelini oluşturma ve eğitme\n",
    "mlp_reg = MLPRegressor(hidden_layer_sizes=(100,), activation='relu', solver='adam', max_iter=200, random_state=42)\n",
    "mlp_reg.fit(X_train, y_train)\n",
    "\n",
    "# Test verileri üzerinde tahmin yapma\n",
    "y_pred = mlp_reg.predict(X_test)\n",
    "\n",
    "# Tahminleri orijinal ölçeğe döndürme\n",
    "y_test_orig = scaler_y.inverse_transform(y_test.reshape(-1, 1))\n",
    "y_pred_orig = scaler_y.inverse_transform(y_pred.reshape(-1, 1))\n",
    "\n",
    "# MSE ve RMSE değerlerini hesaplama\n",
    "mse = mean_squared_error(y_test_orig, y_pred_orig)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(\"Mean Squared Error (MSE): {:.4f}\".format(mse))\n",
    "print(\"Root Mean Squared Error (RMSE): {:.4f}\".format(rmse))\n",
    "\n",
    "# MAE hesaplama\n",
    "mae = mean_absolute_error(y_test_orig, y_pred_orig)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "\n",
    "# MAPE hesaplama\n",
    "mape = mean_absolute_percentage_error(y_test_orig, y_pred_orig) * 100\n",
    "print(\"Mean Absolute Percentage Error (MAPE):\", mape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4ed99599-4134-40d8-8751-a30d55b0ae80",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLPRegressorYPRED= y_pred_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "55c25a3f-b1a1-401b-bf90-2e85ef21b5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.0027\n",
      "Root Mean Squared Error (RMSE): 0.0521\n",
      "Mean Absolute Error (MAE): 0.0416\n",
      "Mean Absolute Percentage Error (MAPE): 0.4021\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Veri setini yükleme ve hazırlama\n",
    "df = pd.read_excel(\"rainfall-and-daily-consumption-data-on-istanbul-dams.xlsx\")\n",
    "df = df[['Tarih', 'İstanbul günlük tüketim(m³/gün)']]\n",
    "df = df.set_index(\"Tarih\")\n",
    "df.index = pd.to_datetime(df.index)\n",
    "df['İstanbul günlük tüketim(m³/gün)'] = df['İstanbul günlük tüketim(m³/gün)'] // 100\n",
    "df['İstanbul günlük tüketim(m³/gün)'] = df['İstanbul günlük tüketim(m³/gün)'].astype(float)\n",
    "df = np.log(df)\n",
    "\n",
    "# Eğitim ve test veri setlerini ayırma\n",
    "train_size = int(len(df) * 0.80)\n",
    "test_size = len(df) - train_size\n",
    "train, test = df.iloc[:train_size], df.iloc[train_size:]\n",
    "\n",
    "# Özellikleri oluşturma\n",
    "def create_features(df):\n",
    "    df = df.copy()\n",
    "    df['dayofweek'] = df.index.dayofweek\n",
    "    df['quarter'] = df.index.quarter\n",
    "    df['month'] = df.index.month\n",
    "    df['year'] = df.index.year\n",
    "    df['dayofyear'] = df.index.dayofyear\n",
    "    return df\n",
    "\n",
    "df = create_features(df)\n",
    "train = create_features(train)\n",
    "test = create_features(test)\n",
    "\n",
    "FEATURES = ['dayofweek', 'quarter', 'month', 'year', 'dayofyear']\n",
    "TARGET = 'İstanbul günlük tüketim(m³/gün)'\n",
    "\n",
    "X_train = train[FEATURES]\n",
    "y_train = train[TARGET]\n",
    "\n",
    "X_test = test[FEATURES]\n",
    "y_test = test[TARGET]\n",
    "\n",
    "# Veriyi normalize etme\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "X_train = scaler_X.fit_transform(X_train)\n",
    "X_test = scaler_X.transform(X_test)\n",
    "\n",
    "y_train = scaler_y.fit_transform(y_train.values.reshape(-1, 1)).ravel()\n",
    "y_test = scaler_y.transform(y_test.values.reshape(-1, 1)).ravel()\n",
    "\n",
    "# SVR modelini oluşturma ve eğitme\n",
    "svr_model = SVR(kernel='rbf', C=100, gamma=0.1, epsilon=.1)\n",
    "svr_model.fit(X_train, y_train)\n",
    "\n",
    "# Test verileri üzerinde tahmin yapma\n",
    "y_pred = svr_model.predict(X_test)\n",
    "\n",
    "# Tahminleri orijinal ölçeğe döndürme\n",
    "y_test_orig = scaler_y.inverse_transform(y_test.reshape(-1, 1))\n",
    "y_pred_orig = scaler_y.inverse_transform(y_pred.reshape(-1, 1))\n",
    "\n",
    "# MSE ve RMSE değerlerini hesaplama\n",
    "mse = mean_squared_error(y_test_orig, y_pred_orig)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(\"Mean Squared Error (MSE): {:.4f}\".format(mse))\n",
    "print(\"Root Mean Squared Error (RMSE): {:.4f}\".format(rmse))\n",
    "\n",
    "# MAE hesaplama\n",
    "mae = mean_absolute_error(y_test_orig, y_pred_orig)\n",
    "print(\"Mean Absolute Error (MAE): {:.4f}\".format(mae))\n",
    "\n",
    "# MAPE hesaplama\n",
    "mape = mean_absolute_percentage_error(y_test_orig, y_pred_orig) * 100\n",
    "print(\"Mean Absolute Percentage Error (MAPE): {:.4f}\".format(mape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ef3c7d41-99dd-49ed-bbc3-887d4314527d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVMYPRED= y_pred_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3075d109-7b65-40f1-9a1d-d721393bb37a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0017945344442359473\n"
     ]
    }
   ],
   "source": [
    "pred_final = (LstmYPRED+MLPRegressorYPRED+SVMYPRED)/3.0\n",
    "print(mean_squared_error(y_test_orig, pred_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a986590-e7b8-40cb-a138-60f87c5a1d5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c92bb2-5675-4574-a7f7-b67bf723df5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631f67ac-24f8-4f2f-9f80-a96af6a3cf9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
